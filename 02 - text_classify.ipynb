{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB,CategoricalNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df=pd.read_csv('centes_marked.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes=df['Is venue, not person']\n",
    "y=classes.dropna().values.astype('int')\n",
    "\n",
    "desc=df['description']\n",
    "corpus=desc.dropna().values.astype('str')[:y.shape[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model_path='sentence-transformers/all-roberta-large-v1'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModel.from_pretrained(model_path).to(device)\n",
    "res=model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def vectorize(sentences):\n",
    "    torch.cuda.empty_cache()\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "\n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    embs=sentence_embeddings.detach().cpu().numpy()\n",
    "    del sentence_embeddings\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return embs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X=[]\n",
    "for sentence in list(corpus):\n",
    "    X.append(vectorize(sentence)[0])\n",
    "X=np.array(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.0001,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "NB = GaussianNB()\n",
    "NB.fit(x_train, y_train)\n",
    "\n",
    "BNB=BernoulliNB()\n",
    "BNB.fit(x_train, y_train)\n",
    "\n",
    "# MNB=MultinomialNB()\n",
    "# MNB.fit(x_train, y_train)\n",
    "\n",
    "CNB=CategoricalNB()\n",
    "CNB.fit(x_train, y_train)\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(x_train, y_train)\n",
    "\n",
    "xgc = XGBClassifier(nthread=2)\n",
    "gistory=xgc.fit(x_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_predict = NB.predict(x_test)\n",
    "y2_predict=BNB.predict(x_test)\n",
    "# y3_predict=MNB.predict(x_test)\n",
    "y4_predict=CNB.predict(x_test)\n",
    "\n",
    "y5_predict = clf.predict(x_test)\n",
    "y6_predict=neigh.predict(x_test)\n",
    "y7_predict = xgc.predict(x_test)\n",
    "\n",
    "print(\"Accuracy Random forest: {:.2f}\".format(rf.score(x_test,y_test)))\n",
    "print(\"Accuracy Normal NB: {:.2f}\".format(NB.score(x_test, y_test)))\n",
    "print(\"Accuracy Bernulli NB: {:.2f}\".format(BNB.score(x_test, y_test)))\n",
    "# print(\"Accuracy Multinominal NB: {:.2f}\".format(MNB.score(x_test, y_test)))\n",
    "print(\"Accuracy Categorical NB: {:.2f}\".format(CNB.score(x_test, y_test)))\n",
    "print(\"Accuracy SVM NB: {:.2f}\".format(accuracy_score(y_test, y5_predict)))\n",
    "print(\"Accuracy Kmeans : {:.2f}\".format(neigh.score(x_test, y_test)))\n",
    "print(\"Accuracy xdboost : {:.2f}\".format(accuracy_score(y_test, y7_predict)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aram_df=pd.read_csv('aram.csv')\n",
    "aram_desc=aram_df['description']\n",
    "del aram_df['Is venue, not person']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "desc_vectors=[]\n",
    "for sentence in list(aram_desc.values.astype('str')):\n",
    "    desc_vectors.append(vectorize(sentence)[0])\n",
    "desc_vectors=np.array(desc_vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_classes=BNB.predict(desc_vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aram_df['Is venue, not person']=predicted_classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aram_df.to_csv('aram_df_marked.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torch",
   "language": "python",
   "display_name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}